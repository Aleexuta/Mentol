The models were run for more datasets, for this you have to modify the name and location of the datasets in each file and the names of the principal columns.

Each datasets is visualized, cleaned and colecting. 
For each dataset I used the text from the post, but the title can be used to with the right modification of the number of words we need to use. 
The notebooks are for just one dataset ( BD2 ). For the results from the BD1 run or see docs.
For RoBerta model I modified the Tokenizer and Clasificator for BERT, RoBERTa, Mental BERT and Mental RoBERTa

**Datasets:**
BD1: https://www.kaggle.com/datasets/kamaruladha/mental-disorders-identification-reddit-nlp
BD2: https://zenodo.org/record/3941387#.ZDOt_nZByMr 
BD3: --TBD--